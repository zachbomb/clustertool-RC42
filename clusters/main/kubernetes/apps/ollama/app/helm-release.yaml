---
# yaml-language-server: $schema=https://kubernetes-schemas.zinn.ca/helm.toolkit.fluxcd.io/helmrelease_v2beta1.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: ollama  # Replace with your namespace
spec:
  interval: 15m
  chart:
    spec:
      chart: ollama  # Replace with the actual chart name if available
      version: 7.11.10  # Replace with appropriate chart version
      sourceRef:
        kind: HelmRepository
        name: truecharts  # Assuming you are using the TrueCharts repository
        namespace: flux-system
  releaseName: ollama
  values:
    credentials:
      s3:
        type: s3
        url: "${S3URL}"
        bucket: "${S3PREFIX}-ollama"
        accessKey: "${S3ID}"
        secretKey: "${S3KEY}"
        encrKey: "${S3KEY}"
    service:
      main:
        enabled: true
        loadBalancerIP: ${OLLAMA_IP}
        targetSelector: ui
        ports:
          main:
            protocol: http
            port: 10686
            targetSelector: ui
        type: LoadBalancer
      api:
        enabled: true
        loadBalancerIP: ${OLLAMA_IP}
        targetSelector: main
        ports:
          api:
            enabled: true
            protocol: http
            targetPort: 11434
            port: 11434
            targetSelector: main
        type: LoadBalancer
  ingress:
    main:
      enabled: true
      integrations:
        traefik:
          enabled: true
          middlewares:
          - name: local
            namespace: traefik
        certManager:
          certificateIssuer: wethecommon-prod-cert
          enabled: true
        homepage:
          description: AI Language Model
          enabled: true
          group: Home Automation
          icon: ""
          name: Ollama

      hosts:
        - host: "ollama.${BASE_DOMAIN}"
          paths:
            - path: /
              pathType: Prefix
      api:
        enabled: false
        targetSelector:
          api: api
    ollama:
      registration:
        enabled: true
        def_user_role: "pending"
      stable_diffusion:
        base_url: ""
      whisper:
        model: "base"
      rag:
        model_device_type: "cpu"
        model: "all-MiniLM-L6-v2"
    workload:
      main:
        podSpec:
          containers:
            main:
              imageSelector: image
              probes:
                liveness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434  # Adjust as needed to point to the correct port
                readiness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434  # Adjust as needed to point to the correct port
                startup:
                  enabled: true
                  type: tcp
                  port: 11434  # Adjust as needed to point to the correct port
      ui:
        enabled: true
        type: Deployment
        podSpec:
          containers:
            ui:
              primary: true
              enabled: true
              imageSelector: uiImage
              resources:
                excludeExtra: true
              probes:
                liveness:
                  enabled: true
                  type: http
                  path: /
                  port: 10686  # Adjust as needed to point to the correct port
                readiness:
                  enabled: true
                  type: http
                  path: /
                  port: 10686  # Adjust as needed to point to the correct port
                startup:
                  enabled: true
                  type: tcp
                  port: 10686  # Adjust as needed to point to the correct port
              env:
                PORT: 10686
                OLLAMA_BASE_URL: 'http://ollama-api:11434'  # Adjust this URL as needed
                WEBUI_SECRET_KEY:
                  secretKeyRef:
                    name: ollama-secrets
                    key: WEBUI_SECRET_KEY
                AUTOMATIC1111_BASE_URL: ""
                ENABLE_SIGNUP: true
                DEFAULT_USER_ROLE: "pending"
                WHISPER_MODEL: "base"
                RAG_EMBEDDING_MODEL: "all-MiniLM-L6-v2"
                RAG_EMBEDDING_MODEL_DEVICE_TYPE: "cpu"
                WEBUI_AUTH_TRUSTED_EMAIL_HEADER: ""
    persistence:
      config:
        enabled: true
        targetSelector:
          main:
            main:
              mountPath: "/root/.ollama"
      data:
        enabled: true
        targetSelector:
          ui:
            ui:
              mountPath: "/app/backend/data"
    portal:
      open:
        enabled: true
